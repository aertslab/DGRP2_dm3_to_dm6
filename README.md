# Create BCF/VCF files with all DGRP2 mutations for Drosophila melanogaster (dm6) from dm3 VCF files

## DGRP2 source data

There are 2 websites with DGRP2 data:
  - [https://www.hgsc.bcm.edu/arthropods/drosophila-genetic-reference-panel](https://www.hgsc.bcm.edu/arthropods/drosophila-genetic-reference-panel): contains a link to a FTP site with DGRP Freeze 2 data ([ftp://ftp.hgsc.bcm.edu/DGRP/freeze2_Feb_2013/](ftp://ftp.hgsc.bcm.edu/DGRP/freeze2_Feb_2013/)).
  - [http://dgrp2.gnets.ncsu.edu/data.html](http://dgrp2.gnets.ncsu.edu/data.html): contains a link to [VCF file for the DGRP Freeze 2.0 calls](http://dgrp2.gnets.ncsu.edu/data/website/dgrp2.vcf).



## Git repository

[https://github.com/aertslab/DGRP2_dm3_to_dm6.git](https://github.com/aertslab/DGRP2_dm3_to_dm6.git)



## Final BCF/VCF files

The generated VCF/BCF DGRP2 files generated by this pipeline can be downloaded from:
[https://resources.aertslab.org/DGRP2/](https://resources.aertslab.org/DGRP2/)



## Required tools

Tools needed for this pipeline:
  - [BCFtools|HTSlib|SAMtools](https://www.htslib.org/)
  - [cURL](https://curl.haxx.se/)
  - [mawk](https://invisible-island.net/mawk/)
  - [picard](http://broadinstitute.github.io/picard/)
  - [vt](https://genome.sph.umich.edu/wiki/Vt)

Version of each tool used for this pipeline:

```bash
module load BCFtools/1.10.2-foss-2018a
module load HTSlib/1.10.2-foss-2018a
module load cURL/7.65.3-GCCcore-6.4.0
module load mawk/1.3.4-20200120-foss-2018a
module load picard/2.21.8-Java-1.8.0
module load SAMtools/1.10-foss-2018a
module load vt/0.57721-foss-2018a
```



## Define variables

Define variables and a function that will be used later.

Make sure that you have set this before executing any code below.

```bash
# Set DGRP2 working directory to a directory of your choice (current dir in this case).
DGRP2_DIR="${PWD}"

# Set variables for storing dm3 and dm6 FASTA filenames (will be downloaded later).
dm3_reference_fasta_filename="${DGRP2_DIR}/tmp/dmel-all-chromosome-r5.13.fasta"
dm6_reference_fasta_filename="${DGRP2_DIR}/tmp/dmel-all-chromosome-r6.22.fasta"

dm3_reference_dict_filename="${dm3_reference_fasta_filename%.fasta}.dict"
dm6_reference_dict_filename="${dm6_reference_fasta_filename%.fasta}.dict"


# Set path to dm3 to dm6 liftOver chain files (will be downloaded or created later).
dm3_to_dm6_ucsc_chroms_chain_filename="${DGRP2_DIR}/tmp/dm3ToDm6.UCSC.over.chain"
dm3_to_dm6_flybase_chroms_chain_filename="${DGRP2_DIR}/tmp/dm3ToDm6.flybase.over.chain"


# Output dirs for different DGRP2 sources.
dgrp2_bcm_hgsc_dir="${DGRP2_DIR}/BCM-HGSC"
dgrp2_ncsu_dir="${DGRP2_DIR}/NCSU"

# Original DGRP2 (source) dm3 VCF files.
dgrp2_bcm_hgsc_source_dm3_vcf_filename="${dgrp2_bcm_hgsc_dir}/DGRP2.source_BCM-HGSC.dm3.vcf"
dgrp2_ncsu_source_dm3_vcf_filename="${dgrp2_ncsu_dir}/DGRP2.source_NCSU.dm3.vcf"

# Final DGRP2 VCF dm6 VCF files.
dgrp2_bcm_hgsc_source_dm6_vcf_filename="${dgrp2_bcm_hgsc_dir}/DGRP2.source_BCM-HGSC.dm6.vcf"
dgrp2_ncsu_source_dm6_vcf_filename="${dgrp2_ncsu_dir}/DGRP2.source_NCSU.dm6.vcf"


# Specify a temporary directory if /tmp is not big enough.
# TMPDIR='/custom/tmp/dir'



# Function to check if any of the programs in a pipe failed.
check_exit_codes () {
    local GET_PIPESTATUS="${PIPESTATUS[@]}";
    local exit_code;

    for exit_code in ${GET_PIPESTATUS} ; do
        if [ ${exit_code} -ne 0 ] ; then
             return ${exit_code};
        fi
    done

    return 0;
}
```



## Download original VCF files

```bash
# Create directories for each source website and a tmp dir.
mkdir -p "${DGRP2_DIR}"/{BCM-HGSC,NCSU,tmp}


# Download DGRP2 BCF-HGSC (source) mutations for Drosophila melanogaster (dm3) from:
# ftp://ftp.hgsc.bcm.edu/DGRP/freeze2_Feb_2013/
curl \
    -R \
    -o "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz" \
    'ftp://ftp.hgsc.bcm.edu/DGRP/freeze2_Feb_2013/vcf_files/freeze2.vcf.gz'

# Decompress DGRP2 BCF-HGSC (source) VFC file as BCFtools has problems reading the compressed file.
gunzip "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz"

# Recompress DGRP2 BCF-HGSC (source) VFC file to save space.
bgzip -l 7 "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}"

# Print location of DGRP2 BCF-HGSC (source) dm3 VCF file.
printf 'DGRP2 BCF-HGSC (source) dm3 VCF file: %s\n' "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz"


# Download DGRP2 mutations for Drosophila melanogaster (dm3) from:
# http://dgrp2.gnets.ncsu.edu/data.html
curl \
    -R \
    -o "${dgrp2_ncsu_source_dm3_vcf_filename}" \
    'http://dgrp2.gnets.ncsu.edu/data/website/dgrp2.vcf'

# Compress DGRP2 NCSU (source) VFC file to save space.
bgzip "${dgrp2_ncsu_source_dm3_vcf_filename}"

# Print location of DGRP2 NCSU (source) dm3 VCF file.
printf 'DGRP2 NCSU (source) dm3 VCF file: %s\n' "${dgrp2_ncsu_source_dm3_vcf_filename}.gz"
```



## Create liftover file for dm3 to dm6 with Flybase chromosome names

### Download files to be able to liftover mutations from dm3 to dm6

```bash
# Download chain file from UCSC to be able to lift over mutations from dm3 to dm6.
curl \
    -R \
    -o "${dm3_to_dm6_ucsc_chroms_chain_filename}.gz" \
    'http://hgdownload.cse.ucsc.edu/goldenPath/dm3/liftOver/dm3ToDm6.over.chain.gz'

# Decompress chain file.
gunzip "${dm3_to_dm6_ucsc_chroms_chain_filename}.gz"


# Download Drosophila melanogaster dm6 assembly report.
# This file is needed to construct mappings from UCSC chromosome names to FlyBase chromosome names as explained at:
# https://groups.google.com/a/soe.ucsc.edu/forum/#!topic/genome/-dUcyIoj_vg
#
# Change Windows line endings to Unix line endings to avoid problems later when parsing the file.
curl 'ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/invertebrate/Drosophila_melanogaster/latest_assembly_versions/GCA_000001215.4_Release_6_plus_ISO1_MT/GCA_000001215.4_Release_6_plus_ISO1_MT_assembly_report.txt' \
  | sed -e 's/\r//g' \
  > "${DGRP2_DIR}/tmp/GCA_000001215.4_Release_6_plus_ISO1_MT_assembly_report.txt"
```

### Convert chain file from UCSC with UCSC chromosome names to Flybase chromosome names

Convert chain file from UCSC with UCSC chromosome names to Flybase chromosome names.

#### Functions for converting UCSC chromosome names to Flybase chromosome names

```bash
# Function to convert Drosophila melanogaster (dm3)
# UCSC chromosme names to FlyBase chromosome names.
convert_dm3_ucsc_chromosomes_to_flybase_chromosomes () {
    local -i chromosome_column="${1}";
    local -i to_flybase_chrom="${2}";

    mawk \
        -v chromosome_column="${chromosome_column}" \
        -v to_flybase_chrom="${to_flybase_chrom}" \
        '
        BEGIN {
            # Set input and output field separator.
            FS=OFS="\t";

            if (to_flybase_chrom == 1) {
                # Make an a array with all UCSC chromosome names as keys
                # and the Flybase chromosome names as values.
                chrom_names_conversion_array["chr2L"] = "2L";
                chrom_names_conversion_array["chr2LHet"] = "2LHet";
                chrom_names_conversion_array["chr2R"] = "2R";
                chrom_names_conversion_array["chr2RHet"] = "2RHet";
                chrom_names_conversion_array["chr3L"] = "3L";
                chrom_names_conversion_array["chr3LHet"] = "3LHet";
                chrom_names_conversion_array["chr3R"] = "3R";
                chrom_names_conversion_array["chr3RHet"] = "3RHet";
                chrom_names_conversion_array["chr4"] = "4";
                chrom_names_conversion_array["chrM"] = "dmel_mitochondrion_genome";
                chrom_names_conversion_array["chrU"] = "U";
                chrom_names_conversion_array["chrUextra"] = "Uextra";
                chrom_names_conversion_array["chrX"] = "X";
                chrom_names_conversion_array["chrXHet"] = "XHet";
                chrom_names_conversion_array["chrYHet"] = "YHet";
            } else {
                # Make an a array with all Flybase chromosome names as keys
                # and the UCSC chromosome names as values.
                chrom_names_conversion_array["2L"] = "chr2L";
                chrom_names_conversion_array["2LHet"] = "chr2LHet";
                chrom_names_conversion_array["2R"] = "chr2R";
                chrom_names_conversion_array["2RHet"] = "chr2RHet";
                chrom_names_conversion_array["3L"] = "chr3L";
                chrom_names_conversion_array["3LHet"] = "chr3LHet";
                chrom_names_conversion_array["3R"] = "chr3R";
                chrom_names_conversion_array["3RHet"] = "chr3RHet";
                chrom_names_conversion_array["4"] = "chr4";
                chrom_names_conversion_array["dmel_mitochondrion_genome"] = "chrM";
                chrom_names_conversion_array["U"] = "chrU";
                chrom_names_conversion_array["Uextra"] = "chrUextra";
                chrom_names_conversion_array["X"] = "chrX";
                chrom_names_conversion_array["XHet"] = "chrXHet";
                chrom_names_conversion_array["YHet"] = "chrYHet";
            }
        }
        {
            if ($chromosome_column in chrom_names_conversion_array) {
                # Convert/replace Flybase chromosomes to UCSC chromosome names or vice versa.
                # Updating chromosome field will also update the $0 variable.
                $chromosome_column = chrom_names_conversion_array[$chromosome_column];
            }

            # Print the original (comment) or modified line of the BED file.
            print $0;
        }';

    return $?;
}



# Function to convert Drosophila melanogaster (dm6)
# UCSC chromosme names to FlyBase chromosome names.
convert_dm6_ucsc_chromosomes_to_flybase_chromosomes () {
    local -i chromosome_column="${1}";
    local -i to_flybase_chrom="${2}";

    flybase_scaffold_file="${DGRP2_DIR}/tmp/GCA_000001215.4_Release_6_plus_ISO1_MT_assembly_report.txt";

    mawk \
        -v flybase_scaffold_file="${flybase_scaffold_file}" \
        -v chromosome_column="${chromosome_column}" \
        -v to_flybase_chrom="${to_flybase_chrom}" \
        '
        BEGIN {
            # Set input and output field separator.
            FS=OFS="\t";

            # Read chromosome names and their corresponding length in an array.
            while ( (getline < flybase_scaffold_file) > 0 ) {
                # Only process non-comment lines.
                if ( $0 !~ /^#/ ) {
                    if (NF != 10) {
                        print "\nERROR: Flybase scaffold file \"" flybase_scaffold_file "\" does not have 10 columns per line.\n" > "/dev/stderr";
                        exit 1;
                    }

                    # Get flybase chromosome name.
                    chrom_flybase = $1;
                    # Get UCSC chromosome name.
                    chrom_ucsc = $10;

                    # For some Flybase chromosomes, we need to remove "chromosome ".
                    gsub(/^chromosome /, "", chrom_flybase);

                    if (to_flybase_chrom == 1) {
                        # Make an a array with all UCSC chromosome names as keys
                        # and the Flybase chromosome names as values.
                        chrom_names_conversion_array[chrom_ucsc] = chrom_flybase;
                    } else {
                        # Make an a array with all Flybase chromosome names as keys
                        # and the UCSC chromosome names as values.
                        chrom_names_conversion_array[chrom_flybase] = chrom_ucsc;
                    }
                }
            }

            if (to_flybase_chrom == 1) {
                chrom_names_conversion_array["chrM"] = "mitochondrion_genome";
            } else {
                chrom_names_conversion_array["mitochondrion_genome"] = "chrM";
            }
        }
        {
            if ($chromosome_column in chrom_names_conversion_array) {
                # Convert/replace Flybase chromosomes to UCSC chromosome names or vice versa.
                # Updating chrom field will also update the $0 variable.
                $chromosome_column = chrom_names_conversion_array[$chromosome_column];
            }

            # Print the original (comment) or modified line of the BED file.
            print $0;
        }';

    return $?;
}
```


#### Convert dm3 to dm6 chain file from UCSC chromosome names to flybase chromosome names

```bash
# Convert dm3 to dm6 chain file from UCSC chromosome names to flybase chromosome names:
#   - With UCSC chromosomes:    chain 990 chr2L 23011544 + 23000773 23003950 chrUn_DS484217v1 2603 - 1692 2273 80065
#   - With FlyBase chromosomes: chain 990 2L 23011544 + 23000773 23003950 211000022280112 2603 - 1692 2273 80065
#   - First change dm3 UCSC chromosomes to dm3 FlyBase chromosomes:
#       convert_dm3_ucsc_chromosomes_to_flybase_chromosomes 3 1
#   - Secondly change dm6 UCSC chromosomes to dm6 FlyBase chromosomes:
#       convert_dm6_ucsc_chromosomes_to_flybase_chromosomes 8 1
mawk '
    {
        if ($1 == "chain") {
            # Print each chain line with TABs instead of spaces
            # (needed for convert_dm{3,6}_ucsc_chromosomes_to_flybase_chromosomes functions).
            OFS="\t";

            # Reassigning column 1 to column 1 forces rebuild of $0 with TABs instead of spaces.
            $1 = $1;
            print $0;
        } else {
            print $0;
        }
    }' "${dm3_to_dm6_ucsc_chroms_chain_filename}" \
    | convert_dm3_ucsc_chromosomes_to_flybase_chromosomes 3 1 \
    | convert_dm6_ucsc_chromosomes_to_flybase_chromosomes 8 1 \
    | mawk '
    {
        if ($1 == "chain") {
            # Print each chain line with spaces instead of TABs.
            OFS=" ";

            # Reassigning column 1 to column 1 forces rebuild of $0 with spaces instead of TABs.
            $1 = $1;
            print $0;
        } else {
            print $0;
        }
    }' > "${dm3_to_dm6_flybase_chroms_chain_filename}"

check_exit_codes || printf 'ERROR: Conversion of UCSC chromosome names to flybase chromosome names in dm3 to dm6 chain file failed.\n'
```


## Get FASTA files for dm3 and dm6 and create dict and index files

Get FASTA files for dm3 and dm6 and create dict and index files.

```bash
# Download dm3 r5.13 FASTA file (which matches with the reference sequence used for DGRP2):
curl \
    -R \
    -o "${dm3_reference_fasta_filename}.gz" \
    ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r5.13_FB2008_10/fasta/dmel-all-chromosome-r5.13.fasta.gz

gunzip "${dm3_reference_fasta_filename}.gz"

# Download dm6 FASTA file:
curl \
    -R \
    -o "${dm6_reference_fasta_filename}.gz" \
    ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r6.22_FB2018_03/fasta/dmel-all-chromosome-r6.22.fasta.gz

gunzip "${dm6_reference_fasta_filename}.gz"


# Create dict file from FASTA.
java \
    -Dpicard.useLegacyParser=false \
    -jar ${EBROOTPICARD}/picard.jar \
    CreateSequenceDictionary \
        -R "${dm3_reference_fasta_filename}" \
        -O "${dm3_reference_dict_filename}"

java \
    -Dpicard.useLegacyParser=false \
    -jar ${EBROOTPICARD}/picard.jar \
    CreateSequenceDictionary \
        -R "${dm6_reference_fasta_filename}" \
        -O "${dm6_reference_dict_filename}"

# Create FASTA index (FAI).
samtools faidx "${dm3_reference_fasta_filename}"
samtools faidx "${dm6_reference_fasta_filename}"
```


## Fix VCF header of DGRP2 (source) dm3 VCF files

Fix VCF header of DGRP2 (source) dm3 VCF files so bcftools can work with it:
  - DGRP2 BCF-HGSC (source) dm3 VCF file:
    - Add chromosome names to VCF header.
    - Remove "mutations" with the same `REF` and `ALT` allele.
  - DGRP2 NCSU (source) dm3 VCF file:
    - Add chromosome names to VCF header.
    - Modify samples names from `line_<number>` to `DGRP-XXX`.

```bash
# Fix header of DGRP2 (source) dm3 VCF file, sort it and convert to BCF format.
fix_dgrp2_source_dm3_vcf_header_and_sort_and_convert_to_bcf () {
    local vcf_input_filename="${1}";
    local bcf_output_filename="${2}";

    # Fix VCF header:
    #   - Add chromosome names to VCF header.
    #   - Modify samples names from "line_<number>" to "DGRP-XXX".
    # Other:
    #   - Remove "mutations" with the same REF and ALT allele.
    #   - Convert VCF file to uncompressed BCF file.
    #   - Sort VCF file and write output in compressed BCF format.
    bcftools reheader \
        --fai "${dm3_reference_fasta_filename}.fai" \
        "${vcf_input_filename}" \
      | mawk \
          -F '\t' \
          -v 'OFS=\t' \
          '
          {
              # Modify samples names from "line_<number>" to "DGRP-XXX".
              if ($1 == "#CHROM") {
                  for (i = 10; i<= NF; i++) {
                      if ($i ~ /^line_/) {
                          $i = sprintf("DGRP-%03d", int(substr($i, 6)));
                      }
                  }
              } else if ($1 !~ /^#/) {
                  # Skip mutations which have the same REF and ALT allele (not a mutation).
                  if ($4 == $5) {
                      next;
                  }
              }

              # Print all modified and unmodified lines.
              print $0;
          }
          ' \
      | bcftools view \
          --output-type u \
          - \
      | bcftools sort \
          --output-type b \
          --output-file "${bcf_output_filename}" \
          --temp-dir="$(mktemp -d "${TMPDIR:-/tmp}/bcftools-sort.XXXXXX")" \
          -

    check_exit_codes;

    return $?
}
```


```bash
# Fix header of DGRP2 BCF-HGSC (source) dm3 VCF file, remove invalid mutations, sort it and convert to BCF format.
fix_dgrp2_source_dm3_vcf_header_and_sort_and_convert_to_bcf \
    "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz" \
    "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.reheader.bcf" \
|| printf 'ERROR: Fixing header of VCF file "%s" failed.\n' "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz"

# Fix header of DGRP2 NCSU (source) dm3 VCF file, sort it and convert to BCF format.
fix_dgrp2_source_dm3_vcf_header_and_sort_and_convert_to_bcf \
    "${dgrp2_ncsu_source_dm3_vcf_filename}.gz" \
    "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.reheader.bcf" \
|| printf 'ERROR: Fixing header of VCF file "%s" failed.\n' "${dgrp2_ncsu_source_dm3_vcf_filename}.gz"
```



## Normalize mutations in DGRP2 dm3 BCF files

Normalize mutations in DGRP2 dm3 BCF files:
  - Left-align and normalize indels.
  - Check if `REF` alleles match the reference.
  - Split multiallelic sites into multiple rows.
  - Update `mutation ID`.
  - Set INFO tags: `AF`, `AC`, `AC_Hemi`, `AC_Hom`, `AC_Het`, `AN`, `ExcHet`, `HWE`, `MAF` and `NS`.

```bash
# Normalize BCF file:
#   - Left-align and normalize indels.
#   - Check if REF alleles match the reference.
#   - Split multiallelic sites into multiple rows.
#   - Update mutation ID.
#   - Set INFO tags: AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
normalize_bcf_file () {
    local bcf_input_filename="${1}";
    local bcf_output_filename="${2}";

    # Normalize BCF file:
    #   - Left-align and normalize indels.
    #   - Check if REF alleles match the reference.
    #   - Split multiallelic sites into multiple rows.
    # Update mutation ID.
    # Set INFO tags: AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
    # Sort uncompressed BCF file.
    # Write compressed BCF file.
    bcftools norm \
        --output-type v \
        --fasta-ref "${dm3_reference_fasta_filename}" \
        --check-ref e \
        --multiallelics -both \
        "${bcf_input_filename}" \
      | mawk \
            -F '\t' \
            -v 'OFS=\t' \
            '
            {
                if ( $1 !~ /^#/ ) {
                    # After the header.

                    # Assign multiple columns a more descriptive name.
                    chrom = $1;
                    pos = $2;
                    ref = $4;
                    alt = $5;

                    # Get length of reference and alternative allele.
                    length_ref = length(ref);
                    length_alt = length(alt);

                    if ( length_ref == 1 && length_alt == 1 ) {
                        # Mutation is a SNP.
                        mutation_type = "SNP";
                    } else if ( length_ref == length_alt ) {
                        # Mutation is a MNP.
                        mutation_type = "MNP";
                    } else if ( length_ref < length_alt ) {
                        # Mutation is a insertion.
                        mutation_type = "INS";
                    } else {
                        # Mutation is a deletion.
                        mutation_type = "DEL";
                    }

                    # Create new ID for the mutation.
                    ID = chrom "_" pos "_" mutation_type "_" ref "_" alt;

                    # Set new ID.
                    $3 = ID;
                }

                print $0;
            }
            ' \
      | bcftools plugin fill-tags \
          --output-type u \
          -- \
          -t all \
      | bcftools sort \
          --output-type u \
          --temp-dir="$(mktemp -d "${TMPDIR:-/tmp}/bcftools-sort.XXXXXX")" \
          - \
      | bcftools view \
          --threads 4 \
          --output-type b \
          --output-file "${bcf_output_filename}" \
          -

    check_exit_codes;

    return $?;
}
```

```bash
# Normalize DGRP2 BCF-HGSC dm3 BCF file.
normalize_bcf_file \
    "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.reheader.bcf" \
    "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.bcf" \
|| printf 'ERROR: Normalization of BCF file "%s" failed.\n' "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.reheader.bcf";

# Output: Lines   total/split/realigned/skipped:  6146594/0/682698/0


# Normalize DGRP2 NCSU dm3 BCF file.
normalize_bcf_file \
    "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.reheader.bcf" \
    "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.bcf" \
|| printf 'ERROR: Normalization of BCF file "%s" failed.\n' "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.reheader.bcf";

# Output: Lines   total/split/realigned/skipped:  4438427/0/268318/0


# Create indexes for normalized DGRP2 dm3 BCF files.
bcftools index "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.bcf"
bcftools index "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.bcf"


# Write statistics for normalized DGRP2 dm3 BCF files.
bcftools stats "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.bcf" > "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.bcf.stats.tsv"
bcftools stats "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.bcf" > "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.bcf.stats.tsv"


# Convert compressed normalized DGRP2 dm3 BCF files to compressed VCF files for Picard.
bcftools view \
    --threads 8 \
    --output-type z \
    --output-file "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" \
    "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.bcf"

bcftools view \
    --threads 8 \
    --output-type z \
    --output-file "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" \
    "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.bcf"


# Create indexes for compressed normalized DGRP2 dm3 VCF files.
bcftools index "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.vcf.gz"
bcftools index "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.vcf.gz"
```



## Lift over normalized mutations from dm3 to dm6

Lift over all mutations from DGRP from dm3 to dm6 which can be lifted over perfectly
(reference should match exactly between dm3 and dm6 unless the alternate allele in dm3 became the reference allele in dm6).
After the lift over we still have to fix some small issues in the lifted over VCF file in the next step.

```bash
# Lift over all mutations from DGRP from dm3 to dm6:
#   - lift over from dm3 to dm6.
#   - perfect liftover (all bases should remap): LIFTOVER_MIN_MATCH=1.0
#   - Swap reference and alternate allele if alternate allele is now the reference sequence in dm6.
liftover_vcf_from_dm3_to_dm6 () {
    local vcf_input_filename="${1}";
    local vcf_output_filename="${2}";

    java \
        -Djava.io.tmpdir="${TMPDIR:-/tmp}" \
        -Dpicard.useLegacyParser=false \
        -jar ${EBROOTPICARD}/picard.jar \
        LiftoverVcf \
            --INPUT "${vcf_input_filename}" \
            --OUTPUT "${vcf_output_filename}" \
            --CHAIN "${dm3_to_dm6_flybase_chroms_chain_filename}" \
            --REJECT "${bcf_output_filename%.bcf}.rejected.vcf.gz" \
            --WARN_ON_MISSING_CONTIG true \
            --LOG_FAILED_INTERVALS true \
            --WRITE_ORIGINAL_POSITION true \
            --WRITE_ORIGINAL_ALLELES true \
            --LIFTOVER_MIN_MATCH 1.0 \
            --ALLOW_MISSING_FIELDS_IN_HEADER false \
            --RECOVER_SWAPPED_REF_ALT true \
            --REFERENCE_SEQUENCE "${dm6_reference_fasta_filename}"

    check_exit_codes;

    return $?;
}
```

```bash
# Lift over mutations from dm3 (after normalization) to dm6 for DGRP2 BCF-HGSC dm3 VCF file.
liftover_vcf_from_dm3_to_dm6 "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"

# Lift over mutations from dm3 (after normalization) to dm6 for DGRP2 NCSU dm3 VCF file.
liftover_vcf_from_dm3_to_dm6 "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"
```

Output:

```
$ liftover_vcf_from_dm3_to_dm6 "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"
21:42:38.196 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/vsc-hard-mounts/leuven-data/software/biomed/skylake_centos7/2018a/software/picard/2.21.8-Java-1.8.0/picard.jar!/com/intel/gkl/native/libgkl_compression.so
[Wed Feb 12 21:42:38 CET 2020] LiftoverVcf  --INPUT /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/BCM-HGSC/DGRP2.source_BCM-HGSC.dm3.norm.vcf.gz --OUTPUT /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/BCM-HGSC/DGRP2.source_BCM-HGSC.dm6.liftover.vcf.gz --CHAIN /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/tmp/dm3ToDm6.flybase.over.chain --REJECT .rejected.vcf.gz --WARN_ON_MISSING_CONTIG true --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION true --WRITE_ORIGINAL_ALLELES true --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT true --REFERENCE_SEQUENCE /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/tmp/dmel-all-chromosome-r6.22.fasta  --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false
[Wed Feb 12 21:42:38 CET 2020] Executing as vsc30366@r23i27n24 on Linux 3.10.0-957.27.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_221-b11; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: Version:2.20.5-SNAPSHOT
INFO    2020-02-12 21:42:38     LiftoverVcf     Loading up the target reference genome.
INFO    2020-02-12 21:42:39     LiftoverVcf     Lifting variants over and sorting (not yet writing the output file.)
INFO    2020-02-12 21:43:17     LiftoverVcf     read     1,000,000 records.  Elapsed time: 00:00:37s.  Time for last 1,000,000:   37s.  Last read position: 2L:14,677,155
INFO    2020-02-12 21:43:34     LiftOver        Interval 2L:22994234-22994237 failed to match chain 676140 because intersection length 1 < minMatchSize 4.0 (0.25 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval 2L:22998093-22998109 failed to match chain 67797 because intersection length 8 < minMatchSize 17.0 (0.47058824 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval 2L:22998093-22998109 failed to match chain 69974 because intersection length 9 < minMatchSize 17.0 (0.5294118 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval 2L:23010970-23010971 failed to match chain 3 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval 2L:23010970-23010971 failed to match chain 3 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval X:100281-100286 failed to match chain 68687 because intersection length 2 < minMatchSize 6.0 (0.33333334 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval X:100281-100286 failed to match chain 127323 because intersection length 4 < minMatchSize 6.0 (0.6666667 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval X:106191-106285 failed to match chain 62049 because intersection length 2 < minMatchSize 95.0 (0.021052632 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval X:106191-106285 failed to match chain 56380 because intersection length 50 < minMatchSize 95.0 (0.5263158 < 1.0)
INFO    2020-02-12 21:43:34     LiftOver        Interval X:109735-109737 failed to match chain 4 because intersection length 1 < minMatchSize 3.0 (0.33333334 < 1.0)
INFO    2020-02-12 21:44:02     LiftoverVcf     read     2,000,000 records.  Elapsed time: 00:01:22s.  Time for last 1,000,000:   45s.  Last read position: X:15,251,516
INFO    2020-02-12 21:44:15     LiftOver        Interval X:20073489-20073493 failed to match chain 4 because intersection length 4 < minMatchSize 5.0 (0.8 < 1.0)
INFO    2020-02-12 21:44:15     LiftOver        Interval X:20082645-20082667 failed to match chain 15237 because intersection length 20 < minMatchSize 23.0 (0.8695652 < 1.0)
INFO    2020-02-12 21:44:15     LiftOver        Interval X:20150365-20150366 failed to match chain 4 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
INFO    2020-02-12 21:44:16     LiftOver        Interval X:21802182-21802184 failed to match chain 4 because intersection length 1 < minMatchSize 3.0 (0.33333334 < 1.0)
INFO    2020-02-12 21:44:16     LiftOver        Interval X:21831006-21831007 failed to match chain 4 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
INFO    2020-02-12 21:44:16     LiftOver        Interval X:21831024-21831062 failed to match chain 4 because intersection length 38 < minMatchSize 39.0 (0.974359 < 1.0)
INFO    2020-02-12 21:44:16     LiftOver        Interval X:21841721-21843158 failed to match chain 4 because intersection length 1437 < minMatchSize 1438.0 (0.9993046 < 1.0)
INFO    2020-02-12 21:44:16     LiftOver        Interval X:21841730-21842092 failed to match chain 4 because intersection length 362 < minMatchSize 363.0 (0.9972452 < 1.0)
INFO    2020-02-12 21:44:38     LiftOver        Interval 3L:5104532-5117712 failed to match chain 2 because intersection length 13081 < minMatchSize 13181.0 (0.99241334 < 1.0)
INFO    2020-02-12 21:44:50     LiftoverVcf     read     3,000,000 records.  Elapsed time: 00:02:11s.  Time for last 1,000,000:   48s.  Last read position: 3L:11,173,835
INFO    2020-02-12 21:45:26     LiftOver        Interval 3L:24532870-24532933 failed to match chain 2 because intersection length 63 < minMatchSize 64.0 (0.984375 < 1.0)
INFO    2020-02-12 21:45:26     LiftOver        Interval 3L:24532915-24532916 failed to match chain 2 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
INFO    2020-02-12 21:45:35     LiftoverVcf     read     4,000,000 records.  Elapsed time: 00:02:55s.  Time for last 1,000,000:   44s.  Last read position: 2R:8,484,117
INFO    2020-02-12 21:46:10     LiftOver        Interval 2R:18708916-18708955 failed to match chain 5 because intersection length 22 < minMatchSize 40.0 (0.55 < 1.0)
INFO    2020-02-12 21:46:10     LiftOver        Interval 2R:18708925-18708937 failed to match chain 5 because intersection length 2 < minMatchSize 13.0 (0.15384616 < 1.0)
INFO    2020-02-12 21:46:10     LiftOver        Interval 2R:18708925-18708943 failed to match chain 5 because intersection length 2 < minMatchSize 19.0 (0.10526316 < 1.0)
INFO    2020-02-12 21:46:10     LiftOver        Interval 2R:18708925-18708979 failed to match chain 5 because intersection length 37 < minMatchSize 55.0 (0.6727273 < 1.0)
INFO    2020-02-12 21:46:10     LiftOver        Interval 2R:18708928-18708973 failed to match chain 5 because intersection length 29 < minMatchSize 46.0 (0.6304348 < 1.0)
INFO    2020-02-12 21:46:17     LiftoverVcf     read     5,000,000 records.  Elapsed time: 00:03:38s.  Time for last 1,000,000:   42s.  Last read position: 3R:7,457,159
INFO    2020-02-12 21:47:06     LiftoverVcf     read     6,000,000 records.  Elapsed time: 00:04:27s.  Time for last 1,000,000:   48s.  Last read position: 3R:25,246,083
INFO    2020-02-12 21:47:18     LiftoverVcf     Processed 6146594 variants.
INFO    2020-02-12 21:47:18     LiftoverVcf     114 variants failed to liftover.
INFO    2020-02-12 21:47:18     LiftoverVcf     4 variants lifted over but had mismatching reference alleles after lift over.
INFO    2020-02-12 21:47:18     LiftoverVcf     0.0019% of variants were not successfully lifted over and written to the output.
INFO    2020-02-12 21:47:18     LiftoverVcf     liftover success by source contig:
INFO    2020-02-12 21:47:18     LiftoverVcf     2L: 1381163 / 1381222 (99.9957%)
INFO    2020-02-12 21:47:18     LiftoverVcf     2R: 1116972 / 1116982 (99.9991%)
INFO    2020-02-12 21:47:18     LiftoverVcf     3L: 1368818 / 1368822 (99.9997%)
INFO    2020-02-12 21:47:18     LiftoverVcf     3R: 1376865 / 1376865 (100.0000%)
INFO    2020-02-12 21:47:18     LiftoverVcf     4: 18877 / 18877 (100.0000%)
INFO    2020-02-12 21:47:18     LiftoverVcf     X: 883781 / 883826 (99.9949%)
INFO    2020-02-12 21:47:18     LiftoverVcf     lifted variants by target contig:
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280112: 3
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280293: 23
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280295: 12
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280297: 5
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280298: 9
INFO    2020-02-12 21:47:18     LiftoverVcf     211000022280657: 1
INFO    2020-02-12 21:47:18     LiftoverVcf     2L: 1381160
INFO    2020-02-12 21:47:18     LiftoverVcf     2R: 1117422
INFO    2020-02-12 21:47:18     LiftoverVcf     3L: 1368818
INFO    2020-02-12 21:47:18     LiftoverVcf     3R: 1376964
INFO    2020-02-12 21:47:18     LiftoverVcf     4: 18778
INFO    2020-02-12 21:47:18     LiftoverVcf     X: 883281
INFO    2020-02-12 21:47:18     LiftoverVcf     13 variants were lifted by swapping REF/ALT alleles.
INFO    2020-02-12 21:47:21     LiftoverVcf     Writing out sorted records to final VCF.
INFO    2020-02-12 21:48:09     LiftoverVcf     written     1,000,000 records.  Elapsed time: 00:00:48s.  Time for last 1,000,000:   48s.  Last read position: 2L:14,677,155
INFO    2020-02-12 21:48:57     LiftoverVcf     written     2,000,000 records.  Elapsed time: 00:01:35s.  Time for last 1,000,000:   47s.  Last read position: 2R:16,921,024
INFO    2020-02-12 21:49:44     LiftoverVcf     written     3,000,000 records.  Elapsed time: 00:02:23s.  Time for last 1,000,000:   47s.  Last read position: 3L:7,946,851
INFO    2020-02-12 21:50:31     LiftoverVcf     written     4,000,000 records.  Elapsed time: 00:03:09s.  Time for last 1,000,000:   46s.  Last read position: 3R:8,984,580
INFO    2020-02-12 21:51:18     LiftoverVcf     written     5,000,000 records.  Elapsed time: 00:03:56s.  Time for last 1,000,000:   47s.  Last read position: 3R:27,696,337
INFO    2020-02-12 21:52:04     LiftoverVcf     written     6,000,000 records.  Elapsed time: 00:04:42s.  Time for last 1,000,000:   45s.  Last read position: X:18,420,758
[Wed Feb 12 21:52:12 CET 2020] picard.vcf.LiftoverVcf done. Elapsed time: 9.56 minutes.
Runtime.totalMemory()=16489381888
```

```
$ liftover_vcf_from_dm3_to_dm6 "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm.vcf.gz" "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"

21:29:51.945 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/vsc-hard-mounts/leuven-data/software/biomed/skylake_centos7/2018a/software/picard/2.21.8-Java-1.8.0/picard.jar!/com/intel/gkl/native/libgkl_compression.so
[Wed Feb 12 21:29:51 CET 2020] LiftoverVcf  --INPUT /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/NCSU/DGRP2.source_NCSU.dm3.norm.vcf.gz --OUTPUT /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/NCSU/DGRP2.source_NCSU.dm6.liftover.vcf.gz --CHAIN /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/tmp/dm3ToDm6.flybase.over.chain --REJECT .rejected.vcf.gz --WARN_ON_MISSING_CONTIG true --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION true --WRITE_ORIGINAL_ALLELES true --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT true --REFERENCE_SEQUENCE /staging/leuven/res_00001/genomes/drosophila_melanogaster/DGRP/tmp/dmel-all-chromosome-r6.22.fasta  --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false
[Wed Feb 12 21:29:51 CET 2020] Executing as vsc30366@r23i27n24 on Linux 3.10.0-957.27.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_221-b11; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: Version:2.20.5-SNAPSHOT
 INFO    2020-02-12 21:29:52     LiftoverVcf     Loading up the target reference genome.
 INFO    2020-02-12 21:29:52     LiftoverVcf     Lifting variants over and sorting (not yet writing the output file.)
 INFO    2020-02-12 21:30:09     LiftoverVcf     read     1,000,000 records.  Elapsed time: 00:00:16s.  Time for last 1,000,000:   16s.  Last read position: 2L:22,121,532
 INFO    2020-02-12 21:30:18     LiftOver        Interval 2L:23010970-23010971 failed to match chain 3 because intersection length 1 < minMatchSize 2.0 (0.5 < 1.0)
 INFO    2020-02-12 21:30:18     LiftOver        Interval X:100281-100286 failed to match chain 68687 because intersection length 2 < minMatchSize 6.0 (0.33333334 < 1.0)
 INFO    2020-02-12 21:30:18     LiftOver        Interval X:100281-100286 failed to match chain 127323 because intersection length 4 < minMatchSize 6.0 (0.6666667 < 1.0)
 INFO    2020-02-12 21:30:30     LiftOver        Interval X:21802182-21802184 failed to match chain 4 because intersection length 1 < minMatchSize 3.0 (0.33333334 < 1.0)
 INFO    2020-02-12 21:30:30     LiftOver        Interval X:21831024-21831062 failed to match chain 4 because intersection length 38 < minMatchSize 39.0 (0.974359 < 1.0)
 INFO    2020-02-12 21:30:34     LiftoverVcf     read     2,000,000 records.  Elapsed time: 00:00:41s.  Time for last 1,000,000:   24s.  Last read position: 3L:8,005,160
 INFO    2020-02-12 21:30:54     LiftoverVcf     read     3,000,000 records.  Elapsed time: 00:01:02s.  Time for last 1,000,000:   20s.  Last read position: 2R:11,134,189
 INFO    2020-02-12 21:31:14     LiftoverVcf     read     4,000,000 records.  Elapsed time: 00:01:21s.  Time for last 1,000,000:   19s.  Last read position: 3R:17,486,812
 INFO    2020-02-12 21:31:23     LiftoverVcf     Processed 4438427 variants.
 INFO    2020-02-12 21:31:23     LiftoverVcf     15 variants failed to liftover.
 INFO    2020-02-12 21:31:23     LiftoverVcf     0 variants lifted over but had mismatching reference alleles after lift over.
 INFO    2020-02-12 21:31:23     LiftoverVcf     0.0003% of variants were not successfully lifted over and written to the output.
 INFO    2020-02-12 21:31:23     LiftoverVcf     liftover success by source contig:
 INFO    2020-02-12 21:31:23     LiftoverVcf     2L: 1013824 / 1013829 (99.9995%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     2R: 824945 / 824946 (99.9999%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     3L: 1001554 / 1001554 (100.0000%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     3R: 986692 / 986692 (100.0000%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     4: 10580 / 10580 (100.0000%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     X: 600817 / 600826 (99.9985%)
 INFO    2020-02-12 21:31:23     LiftoverVcf     lifted variants by target contig:
 INFO    2020-02-12 21:31:23     LiftoverVcf     211000022280293: 1
 INFO    2020-02-12 21:31:23     LiftoverVcf     211000022280295: 9
 INFO    2020-02-12 21:31:23     LiftoverVcf     211000022280297: 5
 INFO    2020-02-12 21:31:23     LiftoverVcf     211000022280298: 3
 INFO    2020-02-12 21:31:23     LiftoverVcf     2L: 1013824
 INFO    2020-02-12 21:31:23     LiftoverVcf     2R: 825006
 INFO    2020-02-12 21:31:23     LiftoverVcf     3L: 1001554
 INFO    2020-02-12 21:31:23     LiftoverVcf     3R: 986718
 INFO    2020-02-12 21:31:23     LiftoverVcf     4: 10554
 INFO    2020-02-12 21:31:23     LiftoverVcf     X: 600738
 INFO    2020-02-12 21:31:23     LiftoverVcf     3 variants were lifted by swapping REF/ALT alleles.
 INFO    2020-02-12 21:31:27     LiftoverVcf     Writing out sorted records to final VCF.
 INFO    2020-02-12 21:31:44     LiftoverVcf     written     1,000,000 records.  Elapsed time: 00:00:16s.  Time for last 1,000,000:   16s.  Last read position: 2L:22,121,532
 INFO    2020-02-12 21:32:01     LiftoverVcf     written     2,000,000 records.  Elapsed time: 00:00:33s.  Time for last 1,000,000:   16s.  Last read position: 3L:3,478,831
 INFO    2020-02-12 21:32:17     LiftoverVcf     written     3,000,000 records.  Elapsed time: 00:00:50s.  Time for last 1,000,000:   16s.  Last read position: 3R:11,690,511
 INFO    2020-02-12 21:32:34     LiftoverVcf     written     4,000,000 records.  Elapsed time: 00:01:06s.  Time for last 1,000,000:   16s.  Last read position: X:6,746,212
 [Wed Feb 12 21:32:41 CET 2020] picard.vcf.LiftoverVcf done. Elapsed time: 2.83 minutes.
 Runtime.totalMemory()=10594287616
```



## Fix lifted over normalized mutations dm6 VCF file

Fix lifted over normalized mutations dm6 DGRP2 VCF files:
  - DGRP2 BCF-HGSC normalized dm6 VCF file:
    - Update `mutation ID`.
    - Add `original mutation ID` to `INFO` tags.
    - Switch `SR` (number of supporting reads) and `OR` (number of opposing reads) counts for alleles that were swappped (`SwappedAlleles` field).
    - Reorder `INFO` tags and `FORMAT` string per sample (`Picard LiftoverVCF` resorted them).
    - Update `INFO` tags (needed for mutations with `SwappedAlleles` field): `AF`, `AC`, `AC_Hemi`, `AC_Hom`, `AC_Het`, `AN`, `ExcHet`, `HWE`, `MAF` and `NS`.
    - Filter out mutations with allele frequency of 0 (can happen for mutations with SwappedAlleles field).
  - DGRP2 NCSU (source) dm3 VCF file:
    - Update `mutation ID`.
    - Add `original mutation ID` to `INFO` tags.
    - Switch `REFCOUNT` and `ALTCOUNT` counts for alleles that were swappped (`SwappedAlleles` field).
    - Reorder `INFO` tags and `FORMAT` string per sample (`Picard LiftoverVCF` resorted them).
    - Update `INFO` tags (needed for mutations with SwappedAlleles field): `AF`, `AC`, `AC_Hemi`, `AC_Hom`, `AC_Het`, `AN`, `ExcHet`, `HWE`, `MAF` and `NS`.
    - Filter out mutations with allele frequency of 0 (can happen for mutations with `SwappedAlleles` field).

```bash
# Fix lifted over dm6 VCF file.
fix_lifted_over_dm6_vcf () {
    local vcf_input_filename="${1}";
    local bcf_output_filename="${2}";

    # Fix lifted over dm6 VCF file:
    #   - Update mutation ID.
    #   - Add original mutation ID to INFO tags.
    #   - Switch SR (number of supporting reads) and OR (number of opposing reads) counts for alleles that were swappped (SwappedAlleles field).
    #   - Switch REFCOUNT and ALTCOUNT counts for alleles that were swappped (SwappedAlleles field).
    #   - Reorder INFO tags and FORMAT string per sample (Picard LiftoverVCF resorted them).
    #   - Update INFO tags (needed for mutations with SwappedAlleles field): AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
    #   - Filter out mutations with allele frequency of 0 (can happen for mutations with SwappedAlleles field).
    #   - Write compressed BCF file.
    bcftools view \
        --threads 2 \
        --output-type v \
        "${vcf_input_filename}" \
      | mawk \
            -F '\t' \
            -v 'OFS=\t' \
            '
            {
                if ( $1 ~ /^##INFO=<ID=OriginalStart/ ) {
                    # Insert "OriginalID" INFO field in header before "OriginalStart".
                    print "##INFO=<ID=OriginalID,Number=1,Type=String,Description=\"The name of the source ID prior to liftover.\">";
                } else if ( $1 !~ /^#/ ) {
                    # After the header.

                    # Assign multiple columns a more descriptive name.
                    chrom = $1;
                    pos = $2;
                    original_ID = $3;
                    ref = $4;
                    alt = $5;
                    format_string = $9;

                    # Get length of reference and alternative allele.
                    length_ref = length(ref);
                    length_alt = length(alt);

                    if ( length_ref == 1 && length_alt == 1 ) {
                        # Mutation is a SNP.
                        mutation_type = "SNP";
                    } else if ( length_ref == length_alt ) {
                        # Mutation is a MNP.
                        mutation_type = "MNP";
                    } else if ( length_ref < length_alt ) {
                        # Mutation is a insertion.
                        mutation_type = "INS";
                    } else {
                        # Mutation is a deletion.
                        mutation_type = "DEL";
                    }

                    # Create new ID for the mutation.
                    new_ID = chrom "_" pos "_" mutation_type "_" ref "_" alt;

                    # Set new ID.
                    $3 = new_ID;

                    # Split INFO string in separate fields.
                    nbr_info_fields = split($8, original_info_array, ";");

                    # Initialize values to keep track of info extracted from the INFO string.
                    ref_count = 0;
                    alt_count = 0;
                    has_ref_count = 0;
                    has_alt_count = 0;
                    has_swapped_alleles = 0;

                    delete new_info_array_order;

                    new_info_array_order[1] = "AF";
                    new_info_array_order[2] = "MAF";
                    new_info_array_order[3] = "NS";
                    new_info_array_order[4] = "AN";
                    new_info_array_order[5] = "AC";
                    new_info_array_order[6] = "AC_Het";
                    new_info_array_order[7] = "AC_Hom";
                    new_info_array_order[8] = "AC_Hemi";
                    new_info_array_order[9] = "ExcHet";
                    new_info_array_order[10] = "HWE";
                    new_info_array_order[11] = "REFCOUNT";
                    new_info_array_order[12] = "ALTCOUNT";
                    new_info_array_order[13] = "OriginalID";
                    new_info_array_order[14] = "OriginalAlleles";
                    new_info_array_order[15] = "OriginalContig";
                    new_info_array_order[16] = "OriginalStart";
                    new_info_array_order[17] = "ReverseComplementedAlleles";
                    new_info_array_order[18] = "SwappedAlleles";

                    new_info_array_order_length = 18;

                    delete new_info_array;

                    new_info_array["AF"] = "";
                    new_info_array["MAF"] = "";
                    new_info_array["NS"] = "";
                    new_info_array["AN"] = "";
                    new_info_array["AC"] = "";
                    new_info_array["AC_Het"] = "";
                    new_info_array["AC_Hom"] = "";
                    new_info_array["AC_Hemi"] = "";
                    new_info_array["ExcHet"] = "";
                    new_info_array["HWE"] = "";
                    new_info_array["REFCOUNT"] = "";
                    new_info_array["ALTCOUNT"] = "";
                    new_info_array["OriginalID"] = "";
                    new_info_array["OriginalAlleles"] = "";
                    new_info_array["OriginalContig"] = "";
                    new_info_array["OriginalStart"] = "";
                    new_info_array["ReverseComplementedAlleles"] = "";
                    new_info_array["SwappedAlleles"] = "";

                    for (i = 1; i <= nbr_info_fields; i++) {
                        current_info_field = original_info_array[i];

                        # Get the position of the equal sign in an info field (if there is one).
                        info_field_equal_sign_pos = index(current_info_field, "=");

                        # Store each field in an array so we can reorder info fields easily later.
                        if ( info_field_equal_sign_pos > 1 ) {
                            # Info field contains an equal sign (so is a key - value field).

                            # Get key name.
                            current_info_field_key = substr(current_info_field, 1, info_field_equal_sign_pos - 1);

                            # Add unknown key at the end of the new_info_array_order array.
                            if ( ! current_info_field_key in new_info_array ) {
                                # Increment the variable that keeps track of the length of the new_info_array_order.
                                new_info_array_order_length += 1;

                                # Add unknown key at the end of the new_info_array_order array.
                                new_info_array_order[new_info_array_order_length] = "current_info_field_key";
                            }

                            # Store whole info field in new_info_array with part before equal sign as key.
                            new_info_array[current_info_field_key] = current_info_field;

                            if ( current_info_field_key == "REFCOUNT" ) {
                                # Get REFCOUNT value.
                                ref_count = substr(current_info_field, 10);

                                has_ref_count = 1;
                            } else if ( current_info_field_key == "ALTCOUNT" ) {
                                # Get ALTCOUNT value.
                                alt_count = substr(current_info_field, 10);

                                has_alt_count = 1;
                            }
                        } else {
                            # Add unknown key at the end of the new_info_array_order array.
                            if ( ! current_info_field in new_info_array ) {
                                # Increment the variable that keeps track of the length of the new_info_array_order.
                                new_info_array_order_length += 1;

                                # Add unknown key at the end of the new_info_array_order array.
                                new_info_array_order[new_info_array_order_length] = "current_info_field";
                            }

                            # Store info field in new_info_array.
                            new_info_array[current_info_field] = current_info_field;

                            if ( current_info_field == "SwappedAlleles" ) {
                                # The alleles swapped (alternate allele became the reference) when doing the liftover
                                # so we have to fix some data which was not corrected by Picard LiftoverVcf.
                                has_swapped_alleles = 1;
                            }
                        }
                    }

                    # Add original ID to INFO fields if not ".".
                    if ( original_ID != "." ) {
                        new_info_array["OriginalID"] = "OriginalID=" original_ID;
                    }

                    if ( format_string == "GT:SR:OR:GQ" ) {
                        # Reorder FORMAT string to "GT:GQ:SR:OR".
                        format_string = "GT:GQ:SR:OR";

                        # Write reordered FORMAT string.
                        $9 = format_string;

                        # Put GQ value after GT value for each sample.
                        for (sample_column = 10; sample_column <= NF; sample_column++) {
                            # Split each sample column values string in separate fields.
                            split($sample_column, sample_column_array, ":");

                            if ( has_swapped_alleles == 1 ) {
                                # Put GQ value after GT value and switch value of SR (number of supporting reads)
                                # and OR (number of opposing reads) as alleles where swapped by Picard LiftoverVcf
                                # but those values were not switched.
                                $sample_column = sample_column_array[1] ":" sample_column_array[4] ":" sample_column_array[3] ":" sample_column_array[2];
                            } else {
                                # Put GQ value after GT value.
                                $sample_column = sample_column_array[1] ":" sample_column_array[4] ":" sample_column_array[2] ":" sample_column_array[3];
                            }
                        }
                    }

                    if ( has_swapped_alleles == 1 && has_ref_count == 1 && has_alt_count == 1 ) {
                        # Switch REFCOUNT and ALTCOUNT INFO field values if they were set in the input and alleles were swapped.
                        new_info_array["REFCOUNT"] = "REFCOUNT=" alt_count;
                        new_info_array["ALTCOUNT"] = "ALTCOUNT=" ref_count;
                    }

                    # Store new reordered INFO string.
                    info_string = "";

                    # Write INFO fields in the order specified in new_info_array_order.
                    for ( i = 1; i <= new_info_array_order_length; i++ ) {
                        # Get the whole info field content of the current requested info field.
                        current_info_field = new_info_array[new_info_array_order[i]];

                        # Only append the content when the info field was set.
                        if ( current_info_field != "" ) {
                            info_string = info_string ";" current_info_field;
                        }
                    }

                    # Remove the leading ";" from the INFO string.
                    info_string = substr(info_string, 2);

                    # Update INFO column.
                    $8 = info_string;
                }

                print $0;
            }
            ' \
      | bcftools plugin fill-tags \
            --threads 2 \
            --output-type u \
            -- \
            -t all \
      | bcftools filter \
            --threads 2 \
            --output-type b \
            --output "${bcf_output_filename}" \
            --exclude 'AF = 0'

    check_exit_codes;

    return $?;
}
```

```bash
# Fix lifted over normalized DGRP2 BCF-HGSC dm6 VCF file.
fix_lifted_over_dm6_vcf \
    "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz" \
    "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf" \
|| printf 'ERROR: Fixing lifted over VCF file "%s" failed.\n' "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz";

# Fix lifted over normalized DGRP2 NCSU dm6 VCF file.
fix_lifted_over_dm6_vcf \
    "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz" \
    "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf" \
|| printf 'ERROR: Fixing lifted over VCF file "%s" failed.\n' "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz";


# Create indexes for final DGRP2 dm6 BCF files.
bcftools index "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf"
bcftools index "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf"

# Write statistics for final DGRP2 dm6 BCF files.
bcftools stats "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf" > "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf.stats.tsv"
bcftools stats "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf" > "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf.stats.tsv"

# Convert final DGRP2 dm6 compressed BCF files to compressed VCF files.
bcftools view \
    --threads 8 \
    --output-type z \
    --output-file "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.vcf.gz" \
    "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf"

bcftools view \
    --threads 8 \
    --output-type z \
    --output-file "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.vcf.gz" \
    "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf"


# Create indexes for final DGRP2 dm6 compressed VCF files.
bcftools index "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.vcf.gz"
bcftools index "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.vcf.gz"
```



## Split final fixed lifted over normalized mutations dm6 BCF file in SNPs and INDELs only files.

Split final fixed lifted over dm6 BCF file in:
  - SNPs only BCF and VCF file.
  - SNPs and decomposed MNPs only BCF and VCF file (for usage with STAR).
  - INDELs only BCF and VCF file.
and calculate statistics for them.

```bash
# Split final fixed lifted over dm6 BCF file in:
#   - SNPs only BCF and VCF file.
#   - SNPs and decomposed MNPs only BCF and VCF file (for usage with STAR).
#   - INDELs only BCF and VCF file.
split_final_fixed_lifted_over_dm6_bcf_in_snps_only_and_indel_only_bcf_files () {
    local bcf_input_filename="${1}";
    local bcf_output_filename="${2}";

    # Extract SNPs only from final fixed dm6 BCF file.
    bcftools view \
        --threads 2 \
        --types snps \
        --output-type b \
        --output-file "${bcf_output_filename%.bcf}.SNPs_only.bcf" \
        "${bcf_input_filename}"

    # Decompose MNPs in individual SNPs (for STAR > 2.6.0):
    #   https://github.com/samtools/bcftools/issues/128
    vt decompose_blocksub \
        "${bcf_input_filename}" \
      | bcftools view \
            --threads 2 \
            --types snps \
            --output-type b \
            --output-file "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.bcf" \
            -

    # Extract INDELs only from final fixed dm6 BCF file.
    bcftools view \
        --threads 2 \
        --types indels \
        --output-type b \
        --output-file "${bcf_output_filename%.bcf}.INDELs_only.bcf" \
        "${bcf_input_filename}"

    # Index all BCF files.
    bcftools index "${bcf_output_filename%.bcf}.SNPs_only.bcf";
    bcftools index "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.bcf";
    bcftools index "${bcf_output_filename%.bcf}.INDELs_only.bcf";

    # Write statistics for all BCF files.
    bcftools stats "${bcf_output_filename%.bcf}.SNPs_only.bcf" > "${bcf_output_filename%.bcf}.SNPs_only.bcf.stats.tsv";
    bcftools stats "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.bcf" >  "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.bcf.stats.tsv";
    bcftools stats "${bcf_output_filename%.bcf}.INDELs_only.bcf" > "${bcf_output_filename%.bcf}.INDELs_only.bcf.stats.tsv";

    # Convert all BCF files to compressed VCF files.
    bcftools view \
        --threads 8 \
        --output-type z \
        --output-file "${bcf_output_filename%.bcf}.SNPs_only.vcf.gz" \
        "${bcf_output_filename%.bcf}.SNPs_only.bcf"

    bcftools view \
        --threads 8 \
        --output-type z \
        --output-file "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.vcf.gz" \
        "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.bcf"

    bcftools view \
        --threads 8 \
        --output-type z \
        --output-file "${bcf_output_filename%.bcf}.INDELs_only.vcf.gz" \
        "${bcf_output_filename%.bcf}.INDELs_only.bcf"

    # Index all compressed VCF files.
    bcftools index "${bcf_output_filename%.bcf}.SNPs_only.vcf.gz";
    bcftools index "${bcf_output_filename%.bcf}.SNPs_and_decomposed_MNPs_only_for_STAR.vcf.gz";
    bcftools index "${bcf_output_filename%.bcf}.INDELs_only.vcf.gz";

}
```

```bash
# Split lifted over normalized DGRP2 BCF-HGSC dm6 final BCF file in SNPs and INDELs.
split_final_fixed_lifted_over_dm6_bcf_in_snps_only_and_indel_only_bcf_files \
    "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf" \
    "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final.bcf"

# Split lifted over normalized DGRP2 NCSU dm6 final BCF file in SNPs and INDELs.
split_final_fixed_lifted_over_dm6_bcf_in_snps_only_and_indel_only_bcf_files \
    "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf" \
    "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final.bcf"
```



## Organize the VCF/BCF files in a nicer structure.

Organize the VCF/BCF files in a nicer structure.

```bash
# DGRP2 BCF-HGSC

# Create needed directories.
mkdir -p ${dgrp2_bcm_hgsc_dir}/{original/dm3,intermediate/{dm3,dm6},final/{dm3,dm6}}

# Original DGRP2 BCF-HGSC dm3 VCF file.
mv "${dgrp2_bcm_hgsc_source_dm3_vcf_filename}.gz" "${dgrp2_bcm_hgsc_dir}/original/dm3"

# Intermediate DGRP2 BCF-HGSC dm3 BCF file:
#   - Add chromosome names to VCF header.
#   - Remove "mutations" with the same REF and ALT allele
#   - Sort
mv "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.reheader.bcf" "${dgrp2_bcm_hgsc_dir}/intermediate/dm3"

# Final normalized DGRP2 BCF-HGSC dm3 VCF/BCF files and statistics:
#   - Left-align and normalize indels.
#   - Check if REF alleles match the reference.
#   - Split multiallelic sites into multiple rows.
#   - Update mutation ID.
#   - Set INFO tags: AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
mv "${dgrp2_bcm_hgsc_source_dm3_vcf_filename%.vcf}.norm."* "${dgrp2_bcm_hgsc_dir}/final/dm3"


# Lifted over normalized DGRP2 BCF-HGSC dm3 VCF file to dm6:
#   - lift over from dm3 to dm6.
#   - perfect liftover (all bases should remap): LIFTOVER_MIN_MATCH=1.0
#   - Swap reference and alternate allele if alternate allele is now the reference sequence in dm6.
mv "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"* "${dgrp2_bcm_hgsc_dir}/intermediate/dm6"

# Final fixed normalized lifted over DGRP2 BCF-HGSC dm6 (all, SNPs, SNPs and decomposed MNPs, and INDELs) VCF/BCF files and statistics:
#   - Update mutation ID.
#   - Add original mutation ID to INFO tags.
#   - Switch SR (number of supporting reads) and OR (number of opposing reads) counts for alleles that were swappped (SwappedAlleles field).
#   - Reorder INFO tags and FORMAT string per sample (Picard LiftoverVCF resorted them).
#   - Update INFO tags (needed for mutations with SwappedAlleles field): AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
#   - Filter out mutations with allele frequency of 0 (can happen for mutations with SwappedAlleles field).
mv "${dgrp2_bcm_hgsc_source_dm6_vcf_filename%.vcf}.final."* "${dgrp2_bcm_hgsc_dir}/final/dm6"
```

```bash
# DGRP2 NCSU

# Create needed directories.
mkdir -p ${dgrp2_ncsu_dir}/{original/dm3,intermediate/{dm3,dm6},final/{dm3,dm6}}

# Original DGRP2 NCSU dm3 VCF file.
mv "${dgrp2_ncsu_source_dm3_vcf_filename}.gz" "${dgrp2_ncsu_dir}/original/dm3"

# Intermediate DGRP2 NCSU dm3 BCF file:
#   - Add chromosome names to VCF header.
#   - Modify samples names from line_<number> to DGRP-XXX.
#   - Sort
mv "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.reheader.bcf" "${dgrp2_ncsu_dir}/intermediate/dm3"

# Final normalized DGRP2 NCSU dm3 VCF/BCF files and statistics:
#   - Left-align and normalize indels.
#   - Check if REF alleles match the reference.
#   - Split multiallelic sites into multiple rows.
#   - Update mutation ID.
#   - Set INFO tags: AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
mv "${dgrp2_ncsu_source_dm3_vcf_filename%.vcf}.norm."* "${dgrp2_ncsu_dir}/final/dm3"


# Lifted over normalized DGRP2 NCSU dm3 VCF file to dm6:
#   - lift over from dm3 to dm6.
#   - perfect liftover (all bases should remap): LIFTOVER_MIN_MATCH=1.0
#   - Swap reference and alternate allele if alternate allele is now the reference sequence in dm6.
mv "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.liftover.vcf.gz"* "${dgrp2_ncsu_dir}/intermediate/dm6"

# Final fixed normalized lifted over DGRP2 NCSU dm6 (all, SNPs, SNPs and decomposed MNPs, and INDELs) VCF/BCF files and statistics:
#   - Update mutation ID.
#   - Add original mutation ID to INFO tags.
#   - Switch REFCOUNT and ALTCOUNT counts for alleles that were swappped (SwappedAlleles field).
#   - Reorder INFO tags and FORMAT string per sample (Picard LiftoverVCF resorted them).
#   - Update INFO tags (needed for mutations with SwappedAlleles field): AF, AC, AC_Hemi, AC_Hom, AC_Het, AN, ExcHet, HWE, MAF and NS.
#   - Filter out mutations with allele frequency of 0 (can happen for mutations with SwappedAlleles field).
mv "${dgrp2_ncsu_source_dm6_vcf_filename%.vcf}.final."* "${dgrp2_ncsu_dir}/final/dm6"
```

